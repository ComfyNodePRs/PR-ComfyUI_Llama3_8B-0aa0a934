# ComfyUI_Llama3_8B
 Llama3_8B for comfyUI， using pipeline workflow
-----

2024-05-05 更新，加入“nvidia/Llama3-ChatQA-1.5-8B”的QA模型节点  
Updated on May 5th, 2024, adding QA model node for "nvidia/Llama3 ChatQA-1.5-8B"   
-----

下载模型,填写repoid，如“X:/meta-llama/Meta-Llama-3-8B-Instruct"的本地绝对路径，开启offline模式，即可使用。   
其他不需要许可的微调模型，可以直接填写，如"gradientai/Llama-3-8B-Instruct-262k"，便直接下载模型。国内用户注意预先下载，我这个节点删除了镜像下载模式     

Download the model,Fill in the repoid, such as the local absolute path of "X:/meta llama/Meta Llama-3-8B Instrument", enable offline mode, and it can be used.  
Other fine-tuning models that do not require permission can be filled in directly, such as "gradientai/Lama-3-8B-Instrument-262k", and the model can be downloaded directly. Domestic users should pay attention to downloading in advance. I have removed the image download mode from this node   

